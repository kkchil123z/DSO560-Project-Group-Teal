{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Fit\", \"Dry Clean Only\",\"Category\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains funcation to generate tags for \"Fit\",\"Dry Clean Only\" and \"Category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import punkt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def lem_sentences(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    lemmed_tokens = [lem.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmed_tokens)\n",
    "\n",
    "#I copy this function from this stackoverflow website\n",
    "# https://stackoverflow.com/questions/43795310/apply-porters-stemmer-to-a-pandas-column-for-each-word\n",
    "\n",
    "def cleanHtml(sentence):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', str(sentence))\n",
    "    return cleantext\n",
    "\n",
    "def keepAlpha(sentence):\n",
    "    alpha_sent = \"\"\n",
    "    for word in word_tokenize(sentence):\n",
    "        alpha_word = re.sub('[^\\w]+', '', word)\n",
    "        alpha_sent += alpha_word\n",
    "        alpha_sent += \" \"\n",
    "    alpha_sent = alpha_sent.strip()\n",
    "    return alpha_sent\n",
    "\n",
    "def cleanPunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = cleaned.strip()\n",
    "    cleaned = cleaned.replace(\"\\n\",\" \")\n",
    "    \n",
    "    return cleaned\n",
    "#The above 4 define function are based on this github page\n",
    "#https://github.com/nkartik94/Multi-Label-Text-Classification/blob/master/Mark_6.ipynb         \n",
    "\n",
    "def cleanComma(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = sentence.strip(',')\n",
    "    cleaned = re.sub(r',{2,}',r',',cleaned)\n",
    "    return cleaned\n",
    "\n",
    "def is_clothing(x):\n",
    "    if x in cloth_list:\n",
    "        return 1\n",
    "    elif x in non_cloth_list:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the tf-idf vecotirzer used for every classification model here\n",
    "stop_list=stopwords.words('english')\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,3),\n",
    "                             token_pattern=r'\\b[a-zA-Z0-9]{3,}\\b',\n",
    "                             max_df=0.5,\n",
    "                             min_df=10, stop_words=stop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(brand,brand_category,product_full_name,description,details):\n",
    "    input_text= brand+' '+brand_category+' '+product_full_name+' '+description+' '+details\n",
    "    input_text=input_text.strip().lower()\n",
    "    #Using Lemmatization to keep the original form of word\n",
    "    input_text=lem_sentences(input_text)\n",
    "    #clean the html sign since it would not give us insight\n",
    "    input_text=cleanHtml(input_text)\n",
    "    #removing special chracter such as trademark\n",
    "    input_text=keepAlpha(input_text)\n",
    "    #clean punctuation\n",
    "    input_text=cleanPunc(input_text)\n",
    "    input_text =pd.Series(input_text)\n",
    "    return input_text\n",
    "\n",
    "\n",
    "def clothing_or_not(brand,brand_category,product_full_name,description,details):\n",
    "    #this function determine if an itme is a clothing or not\n",
    "    input_text=text_preprocessing(brand,brand_category,product_full_name,description,details)\n",
    "    X_cloth=is_clothing_df['input']\n",
    "    y_cloth=is_clothing_df['clothing']\n",
    "\n",
    "    SVC_pipeline_cloth = Pipeline([('tfidf1', vectorizer),\n",
    "                ('clf1', LinearSVC()),])\n",
    "\n",
    "    SVC_pipeline_cloth.fit(X_cloth, y_cloth)\n",
    "    prediction = SVC_pipeline_cloth.predict(input_text)\n",
    "    return prediction\n",
    "\n",
    "def clothing_fit_tag(brand,brand_category,product_full_name,description,details):\n",
    "    #this function determine the fit tags for clothing item\n",
    "    item_is_clothing = clothing_or_not(brand,brand_category,product_full_name,description,details)\n",
    "    if item_is_clothing == 1:\n",
    "        input_text=text_preprocessing(brand,brand_category,product_full_name,description,details)\n",
    "        X_fit=fit_tags['input']\n",
    "        y_fit=fit_tags['attribute_value']\n",
    "\n",
    "        GradientFC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', OneVsRestClassifier(GradientBoostingClassifier())),\n",
    "            ])\n",
    "\n",
    "        GradientFC_pipeline.fit(X_fit, y_fit)\n",
    "        prediction = GradientFC_pipeline.predict(input_text)\n",
    "        return prediction\n",
    "    else:\n",
    "        return \"\"\n",
    "        \n",
    "def clothing_dryclean_tag(brand,brand_category,product_full_name,description,details):\n",
    "    #this function determine if a clothing item is dry_clean_only\n",
    "    item_is_clothing = clothing_or_not(brand,brand_category,product_full_name,description,details)\n",
    "    if item_is_clothing == 1:\n",
    "        input_text=text_preprocessing(brand,brand_category,product_full_name,description,details)\n",
    "        X_dryclean=dryclean_tags['input']\n",
    "        y_dryclean=dryclean_tags['dry_clean']\n",
    "\n",
    "\n",
    "        GradientFC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', GradientBoostingClassifier()),\n",
    "            ])\n",
    "\n",
    "        GradientFC_pipeline.fit(X_dryclean, y_dryclean)\n",
    "        prediction = GradientFC_pipeline.predict(input_text)\n",
    "        if prediction == 1:\n",
    "            return 'yes'\n",
    "        else:\n",
    "            return 'no'\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    \n",
    "def item_category_tag(brand,brand_category,product_full_name,description,details):\n",
    "    # this function determine which category an item belong to\n",
    "    input_text=text_preprocessing(brand,brand_category,product_full_name,description,details)\n",
    "    X_category=category_tags['input']\n",
    "    y_category=category_tags['attribute_category']\n",
    "\n",
    "\n",
    "    SVC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', LinearSVC()),])\n",
    "\n",
    "    SVC_pipeline.fit(X_category, y_category)\n",
    "    prediction = SVC_pipeline.predict(input_text)\n",
    "    if prediction == 'other':\n",
    "        # item such as sunglass, belt, accessory, and case belongs to \"other\" category\n",
    "        return \"\"\n",
    "    else:\n",
    "        return prediction\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_data = pd.read_csv('tagged_product_attributes.csv')\n",
    "full_data = pd.read_csv('full_data.csv')\n",
    "\n",
    "#the following dataset is derived from the above two dataset\n",
    "#These dataset would be used for model fiting latter\n",
    "is_clothing_df=pd.read_csv('is_clothing_or_not.csv', index_col=0)\n",
    "fit_tags=pd.read_csv('fit_tags.csv', index_col=0)\n",
    "dryclean_tags=pd.read_csv('dryclean_tags.csv', index_col=0)\n",
    "category_tags=pd.read_csv('category_tags.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This item is a sunglasses\n",
    "brand4=full_data.loc[4]['brand']\n",
    "brand_category4=full_data.loc[4]['brand_category']\n",
    "product_full_name4=full_data.loc[4]['product_full_name']\n",
    "description4=full_data.loc[4]['description']\n",
    "details4=full_data.loc[4]['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This item is pants\n",
    "brand10=full_data.loc[10]['brand']\n",
    "brand_category10=full_data.loc[10]['brand_category']\n",
    "product_full_name10=full_data.loc[10]['product_full_name']\n",
    "description10=full_data.loc[10]['description']\n",
    "details10=full_data.loc[10]['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_fit_tag(brand4,brand_category4,product_full_name4,description4,details4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_dryclean_tag(brand4,brand_category4,product_full_name4,description4,details4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_category_tag(brand4,brand_category4,product_full_name4,description4,details4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['straight/regular'], dtype='<U16')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_fit_tag(brand10,brand_category10,product_full_name10,description10,details10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing_dryclean_tag(brand10,brand_category10,product_full_name10,description10,details10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bottom'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_category_tag(brand10,brand_category10,product_full_name10,description10,details10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate columns for \"Fit\", \"Dry Clean Only\", and \"Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48979, 13)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the column to get the input text\n",
    "full_data ['input']=full_data[['brand','brand_category','product_full_name','description','details']].fillna('')\\\n",
    ".agg(' '.join, axis=1).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the text\n",
    "full_data['input']= full_data['input'].apply(lem_sentences)\n",
    "full_data['input'] = full_data['input'].apply(cleanHtml)\n",
    "full_data['input']= full_data['input'].apply(cleanPunc)\n",
    "full_data['input'] = full_data['input'].apply(keepAlpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_text=full_data['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to see if an item is clothing or not\n",
    "X=is_clothing_df['input']\n",
    "y=is_clothing_df['clothing']\n",
    "\n",
    "SVC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', LinearSVC()),\n",
    "            ])\n",
    "\n",
    "SVC_pipeline.fit(X, y)\n",
    "prediction_cloth = SVC_pipeline.predict(full_text)\n",
    "full_data['clothing']=prediction_cloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the \"fit\" tag for clothing item\n",
    "X_fit=fit_tags['input']\n",
    "y_fit=fit_tags['attribute_value']\n",
    "\n",
    "GradientFC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', OneVsRestClassifier(GradientBoostingClassifier())),\n",
    "            ])\n",
    "\n",
    "GradientFC_pipeline.fit(X_fit, y_fit)\n",
    "prediction_fit = GradientFC_pipeline.predict(full_text)\n",
    "full_data['fit']=prediction_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"dry clean only\" tag for clothing item\n",
    "X_dryclean=dryclean_tags['input']\n",
    "y_dryclean=dryclean_tags['dry_clean']\n",
    "\n",
    "\n",
    "GradientFC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', GradientBoostingClassifier()),\n",
    "            ])\n",
    "\n",
    "GradientFC_pipeline.fit(X_dryclean, y_dryclean)\n",
    "prediction_dryclean = GradientFC_pipeline.predict(full_text)\n",
    "\n",
    "full_data['dry_clean_only']=prediction_dryclean\n",
    "full_data['dry_clean_only']=np.where(full_data['dry_clean_only']==1,'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the \"category\" tag for every item\n",
    "X_category=category_tags['input']\n",
    "y_category=category_tags['attribute_category']\n",
    "\n",
    "\n",
    "SVC_pipeline = Pipeline([('tfidf', vectorizer),\n",
    "                ('clf', LinearSVC()),])\n",
    "\n",
    "SVC_pipeline.fit(X_category, y_category)\n",
    "prediction_category = SVC_pipeline.predict(full_text)\n",
    "full_data['category']=prediction_category\n",
    "full_data['category']=np.where(full_data['category']!='other',full_data['category'],\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['fit']=np.where(full_data['clothing']==1,full_data['fit'],'')\n",
    "full_data['dry_clean_only']=np.where(full_data['clothing']==1,full_data['dry_clean_only'],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the record in the training data, get the real tag\n",
    "full_data2=full_data.merge(fit_tags[['product_id','attribute_value']],on='product_id',how='left')\n",
    "full_data3=full_data2.merge(dryclean_tags[['product_id','attribute_value']],on='product_id',how='left',suffixes=['_fit','_dc'])\n",
    "full_data4=full_data3.merge(category_tags[['product_id','attribute_category']],on='product_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data4['fit']=np.where(full_data4['attribute_value_fit'].isna(),full_data4['fit'],full_data4['attribute_value_fit'])\n",
    "full_data4['dry_clean_only']=np.where(full_data4['attribute_value_dc'].isna(),full_data4['dry_clean_only'],\\\n",
    "                                      full_data4['attribute_value_dc'])\n",
    "full_data4['category']=np.where(full_data4['attribute_category'].isna(),full_data4['category'],full_data4['attribute_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data5=full_data4.drop(['attribute_value_fit','attribute_value_dc','attribute_category','clothing','input'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data5.to_csv('full_data_with_3_columns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
